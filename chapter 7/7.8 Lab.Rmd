---
title: "7.8 Lab"
output:
  html_document:
    df_print: paged
---

```{r}
library(ISLR)
```
## Polynomial Regression and Step Functions

```{r}
fit = lm( wage~poly(age,4), data = Wage)
coef(summary(fit))
```
```{r}
fit2 = lm( wage~poly(age,4,raw = T), data = Wage)
coef(summary(fit2))
```
```{r}
fit2a =  lm( wage~age+I(age^2)+I(age^3)+I(age^4), data = Wage)
coef(summary(fit2a))
```
```{r}
fit2b =  lm( wage~cbind(age,age^2,age^3,age^4), data = Wage)
coef(summary(fit2b))
```
Clearly, all the 4 ways give us the same results
```{r}
agelims = range(Wage$age)
age.grid = seq( from=agelims[1], to=agelims[2])
preds = predict(fit, newdata = list(age = age.grid), se = T)
se.bands = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
```
```{r}
par( mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot( Wage$age, Wage$wage, xlim = agelims, cex=0.5, col="darkgrey")
title("Degree-4 polynomial", outer = T)
lines( age.grid, preds$fit, lwd=2, col="blue")
matlines( age.grid, se.bands, lwd=1, col="blue", lty=3)
```
To see how raw parameter effects in the poly() function affects the model,
```{r}
preds2 = predict(fit2, newdata = list(age = age.grid), se=T)
max(abs(preds$fit-preds2$fit))
```
Clearly, the models have very little difference in terms of prediction capability

Now, we try to decide the degree of polynomial to use through the anova() function i.e analysis of variance
```{r}
fit.1 = lm(wage~age, data = Wage)
fit.2 = lm(wage~poly(age,2), data = Wage)
fit.3 = lm(wage~poly(age,3), data = Wage)
fit.4 = lm(wage~poly(age,4), data = Wage)
fit.5 = lm(wage~poly(age,5), data = Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
```
So, eithera cubic or a quartic function appears to be a good fit
```{r}
coef(summary(fit.5))
```
We can use anova() even when we have other predictors along with age
```{r}
fit.e1 = lm(wage~education+age, data = Wage)
fit.e2 = lm(wage~education+poly(age,2), data = Wage)
fit.e3 = lm(wage~education+poly(age,3), data = Wage)
anova(fit.e1, fit.e2, fit.e3)
```
Instead of annova() and hypothesis tests, we can use cross-validation as well

Now, we consider predicting whether an individual will earn more than $250,000 per year
```{r}
c.fit = glm( I(wage>250)~poly(age,4), data = Wage, family = "binomial")
c.preds = predict(c.fit, newdata=list(age=age.grid), se=T)
c.pfit = exp(c.preds$fit)/(1+exp(c.preds$fit))
c.se.bands.logit = cbind(c.preds$fit+2*c.preds$se.fit, c.preds$fit-2*c.preds$se.fit)
c.se.bands = exp(c.se.bands.logit)/(1+exp(c.se.bands.logit))

plot(Wage$age, I(Wage$wage>250), xlim = agelims, type = "n", ylim = c(0,0.2))
points(jitter(Wage$age), I((Wage$wage > 250)/5), cex = 0.5, pch = "|", col = "darkgrey")
lines(age.grid, c.pfit, lwd = 2, col = "blue")
matlines(age.grid, c.se.bands, lwd = 1, col = "blue", lty=3)
```
Now, for step functions
```{r}
table( cut(Wage$age, 4))
```
```{r}
stepfit = lm(wage~cut(age,4), data = Wage)
coef(summary(stepfit))
```
We can specify our own cutpoints using breaks option. Plotting the step function like the polynomial one, we get 
```{r}
step.preds = predict(stepfit, newdata = list(age = age.grid), se = T)
step.se.bands = cbind(step.preds$fit+2*step.preds$se.fit, step.preds$fit-2*step.preds$se.fit)

plot( Wage$age, Wage$wage, xlim = agelims, cex=0.5, col="darkgrey")
lines( age.grid, step.preds$fit, lwd=2, col="blue")
matlines( age.grid, step.se.bands, lwd=1, col="blue", lty=3)
```
## Splines

```{r}
library(splines)
sp.fit = lm(wage~bs(age,knots=c(25,40,60)), data = Wage)
sp.pred = predict(sp.fit, newdata=list(age=age.grid), se=T)


plot(Wage$age, Wage$wage, col = "grey")
lines(age.grid, sp.pred$fit, lwd = 2)
lines(age.grid, sp.pred$fit+2*sp.pred$se.fit, lty = "dashed")
lines(age.grid, sp.pred$fit-2*sp.pred$se.fit, lty = "dashed")
```
```{r}
dim(bs(Wage$age, knots = c(25,40,60)))
dim(bs(Wage$age, df = 6)) #df stands for degrees of freedom
attr(bs(Wage$age, df = 6), "knots") #to get the autoselected knots
```
For natural spline,
```{r}
ns.fit = lm(wage~ns(age, df=4), data = Wage)
ns.pred = predict(ns.fit, newdata=list(age=age.grid), se=T)

plot(Wage$age, Wage$wage, col = "grey")
lines(age.grid, ns.pred$fit, col="red", lwd=2)
```
For smoothing spline
```{r}
ss.fit = smooth.spline(Wage$age, Wage$wage, df=16)
ss.fit2 = smooth.spline(Wage$age, Wage$wage, cv=T)
ss.fit2$df
```
```{r}
plot(Wage$age, Wage$wage, xlim=agelims, cex=0.5, col="darkgrey")
title("Smoothing Spline")
lines(ss.fit, col="red", lwd=2)
lines(ss.fit2, col="blue", lwd=2)
legend("topright", legend = c("16 df","6.8 df"), col=c("red","blue"), lty=1, lwd=2, cex=0.8)
```
For local regression,
```{r}
lor.fit = loess(wage~age, span = 0.2, data = Wage)
lor.fit2 = loess(wage~age, span = 0.5, data = Wage)

plot(Wage$age, Wage$wage, xlim=agelims, cex=0.5, col="darkgrey")
title("Local Regression")
lines(age.grid, predict(lor.fit, data.frame(age=age.grid)), col="red", lwd=2)
lines(age.grid, predict(lor.fit2, data.frame(age=age.grid)), col="blue", lwd=2)
legend("topright", legend = c("span=0.2","span=0.5"), col=c("red","blue"), lty=1, lwd=2, cex=0.8)
```
## GAM

```{r}
gam1 = lm(wage~ns(year,4)+ns(age,5)+education, data = Wage)
coef(summary(gam1))
```
To use smoothing splines in GAM, we need the gam library
```{r}
library(gam)
gam.m3 = gam(wage~s(year,4)+s(age,5)+education, data = Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=T, col="blue")
```
```{r}
par(mfrow=c(1,3))
plot.Gam(gam1, se = T, col="red")
```
```{r}
gam.m1 = gam(wage~s(age,5)+education, data = Wage)
gam.m2 = gam(wage~year+s(age,5)+education, data = Wage)
anova(gam.m1, gam.m2, gam.m3)
```
```{r}
summary(gam.m3)
```
For using local regression in GAMs, we use lo() function
```{r}
gam.lo = gam(wage~s(year,4)+lo(age, span = 0.7)+education, data = Wage)
par(mfrow=c(1,3))
plot.Gam(gam.lo, se=T, col="green")
```
```{r}
gam.lo.i = gam(wage~lo(age, year, span=0.5)+education, data = Wage)
library(akima)
par(mfrow=c(1,2))
plot.Gam(gam.lo.i, col="yellow")
```
For logarithmic regressions in GAM, we use I() function and set the family as binomial. We remove "1. < HS Grad" becuase there are no high earners in that category
```{r}
gam.lr = gam( I(wage>250)~year+s(age,df=5)+education, family = binomial, data = Wage,
              subset = (education!="1. < HS Grad"))
par(mfrow=c(1,3))
plot(gam.lr, se=T, col="green")

```
